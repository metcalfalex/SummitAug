# SummitAug
August summit notes

Test


Boon = Joelle

HEX = analytics as a service

Data at REST

nifi

zepplin

spark = in memory analytics (big data or any data)

cloudera = #1 
hortonworks = #2

How do I get ahead in this area?
How do I get certified?

linux (SSH)
HDP (HDFS, Hive, Spark)
HDF (nifi)
Zeppelin (SQL, Python, Spark UI)

cassino data
roulette
Use case?

yahoo finance API


github.com/metcalfalex/SummitAug


1. agile ideation - use case?
2. develop POC
3. present


Add > hortonworks sandbox > 

Can get a static IP for extra $$

13.73.197.70:8888

tss2
tss2P@ssword

yum - for installatoins

if need to install
sudo bash
sudo root

map reduce = framework
works in the back end, don't need to worry about it. can write java scripts to 


oozie - data out
spoop - data in

zoo keeper - admin tool ontop of kafta, if doing api/web cools
kafta - resource management

atlas - query metadata from the hdfs

nifi - 

zepplin - spark, in memorry processing of batch or steam

spark - engine (set based analysis)
zepplin - shell/ui, like a jupyter notebook

hdfs, hive, spark, mapreduce

ranger - security

hadoop -> hdfs -> hive db -> vis tabl

whoami
wget

!!! Get commands he used onscreen (.txt)

opening ports
e.g. R, rstudio ports were not open


File in:
 - bash
 - ambari

hdfs - breaks up 'blocks' of the file - not 'rows' of a data file

HIVE
create hive table

'\073' - semi-colon (as opposed to traditional comma)

can automate create table statement by stipping first row of file

create table - think of as a view over the actual file

tez - alternative to map reduce, good performance on single node

tez - speeds up queries

hbase can partition

don't use any reserved keywords

getting data out:
create table as select x from y where z = abc



